{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     # Purchases  B01001001   B01001002  B01001003  B01001004  B01001005  \\\n",
      "0             22     206252  469.226965  31.432422  35.219052  33.628765   \n",
      "1              7      61399  486.538869  22.899396  21.531295  27.036271   \n",
      "2              3      73170  489.859232  28.905289  36.271696  28.235616   \n",
      "3             94     251724  505.585483  32.054949  31.757004  28.102207   \n",
      "4              0      37382  495.586111  25.413301  29.318924  26.162324   \n",
      "5             19     230108  499.217759  32.767222  35.465955  36.169972   \n",
      "6             11     928405  493.339652  28.576968  30.484541  33.556476   \n",
      "7              2      15890  498.237886  32.473254  34.675897  36.752675   \n",
      "8              0      24327  475.562133  30.007810  29.514531  31.158795   \n",
      "9           2861   19979950  483.276184  31.650830  30.824702  31.484864   \n",
      "10             1     247408  500.820507  44.072948  43.862769  41.506338   \n",
      "11           133     318227  497.654190  27.904609  29.309267  30.657361   \n",
      "12             2      83613  479.937330  40.484135  38.714076  37.039695   \n",
      "13             3     146360  509.162339  24.856518  30.725608  27.405029   \n",
      "14            48     395285  514.380763  38.202816  35.860202  36.975853   \n",
      "15             0      38055  488.634871  38.181579  32.558140  32.584417   \n",
      "16           124     877846  488.967313  26.980814  28.309066  30.156770   \n",
      "17             2      37319  489.027037  33.012675  34.727619  34.164903   \n",
      "18             1     106698  492.164802  28.276069  30.750342  31.696939   \n",
      "19             3      20956  493.987402  22.380225  32.639817  29.394923   \n",
      "20            51     112221  491.565750  31.304301  35.358801  36.392476   \n",
      "21            14     178302  480.460118  35.456697  34.923893  37.133627   \n",
      "22            15     336811  480.079332  25.533608  28.146349  25.483134   \n",
      "23             6      93586  518.784861  26.798880  23.603958  25.131964   \n",
      "24             1      51213  491.730615  23.080077  26.126179  26.282389   \n",
      "25             1      66204  474.790043  27.354843  30.194550  29.197632   \n",
      "26             2      72386  495.385848  28.458542  27.242837  31.069544   \n",
      "27             0     107194  493.796295  26.559322  27.212344  28.686307   \n",
      "28             3      45986  493.432784  35.293350  30.791980  45.361632   \n",
      "29             6     118947  520.189664  44.053234  37.823568  27.482828   \n",
      "..           ...        ...         ...        ...        ...        ...   \n",
      "702           59    1135734  484.210211  27.203553  27.141038  32.092902   \n",
      "703            2      39255  539.447204  33.447968  32.174245  33.549866   \n",
      "704            9     279748  503.706908  27.349615  29.108340  28.822369   \n",
      "705           12     135477  517.135750  25.768212  24.653631  23.981931   \n",
      "706            9     314263  486.840640  32.227784  33.891995  31.569100   \n",
      "707           22     225070  484.218243  28.324521  28.337850  28.155685   \n",
      "708            0      45484  492.524844  30.867998  29.702753  40.036057   \n",
      "709           17     467348  501.521350  30.379931  30.204473  31.051807   \n",
      "710            0      25699  498.774271  40.429589  34.086929  33.114129   \n",
      "711            5     186246  480.762003  33.208767  33.788645  37.761885   \n",
      "712         1464    9534008  488.834601  32.456864  33.874421  34.898334   \n",
      "713           10     200685  494.182425  39.524628  39.340260  41.502853   \n",
      "714            4      98328  488.101049  25.109836  25.842080  25.486128   \n",
      "715           40     852631  486.918726  31.388725  33.407183  32.615516   \n",
      "716            3     150002  474.753670  29.626272  31.806243  35.439527   \n",
      "717            0      36598  495.081699  36.532051  40.357397  33.635718   \n",
      "718           95    1261936  487.955015  31.984189  31.954077  34.534239   \n",
      "719          883    5949403  488.116371  34.265959  33.027852  32.530155   \n",
      "720            4     248292  491.989271  26.396340  28.112062  30.347333   \n",
      "721            1      33462  485.984101  29.526030  32.813341  31.199570   \n",
      "722           37     862224  482.100939  27.293372  28.617853  32.564624   \n",
      "723            2      70224  488.935407  36.127250  35.301321  34.589314   \n",
      "724            2      61004  489.623631  31.309422  34.637073  32.079864   \n",
      "725            1      41878  530.421701  25.550408  26.123502  32.427528   \n",
      "726            4      45906  528.994031  25.072975  26.576047  27.556311   \n",
      "727            4      38106  482.312497  26.242586  21.072797  27.213562   \n",
      "728            3      32531  511.665796  31.908026  33.875380  28.618856   \n",
      "729            3      38761  493.511519  32.558500  38.260107  29.075617   \n",
      "730            1      28359  496.773511  36.954759  42.843542  32.793822   \n",
      "731          507    5861000  484.835011  29.037878  29.160212  29.654325   \n",
      "\n",
      "     B01001006  B01001007  B01001008  B01001009     ...      B19001008  \\\n",
      "0    20.121017  12.610787   6.734480   6.225394     ...      49.409690   \n",
      "1    16.808091  28.355511  18.192479  13.534422     ...      59.231680   \n",
      "2    21.566216  12.218122   7.243406   7.380074     ...      63.996993   \n",
      "3    18.651380  12.080692   7.035483   7.686991     ...      54.790900   \n",
      "4    19.260607  12.893906   6.580707   7.062222     ...      58.883378   \n",
      "5    22.107011  13.593617   5.671250   6.144941     ...      46.201509   \n",
      "6    21.172872  15.826067   7.983585   7.764930     ...      37.631856   \n",
      "7    26.557583  17.747011   4.845815  16.362492     ...      32.177704   \n",
      "8    18.950138  27.335882  13.318535  16.771488     ...      46.472856   \n",
      "9    19.676576  12.867249   6.957375   6.725342     ...      36.342018   \n",
      "10   24.295900  16.058494   9.470187   7.465401     ...      59.383284   \n",
      "11   17.892888  18.540224  11.520078  14.734765     ...      48.490467   \n",
      "12   21.384235  12.211020   7.558633   5.645055     ...      43.639801   \n",
      "13   18.140202  11.253075   6.415687   5.677781     ...      56.221607   \n",
      "14   21.629963  14.718494   9.357805   9.767636     ...      37.190052   \n",
      "15   18.446985  16.134542   8.671659   7.646827     ...      45.918717   \n",
      "16   19.256225  17.536105   9.026640   8.821593     ...      41.894517   \n",
      "17   20.740106  13.076449   6.940165   7.422493     ...      61.664190   \n",
      "18   19.916025  11.162346   5.688954   6.832368     ...      50.958338   \n",
      "19   20.614621  11.643443   2.385952   2.767704     ...      60.689503   \n",
      "20   21.546769  15.781360   9.142674   6.317891     ...      43.737769   \n",
      "21   22.153425  13.763166   7.369519   8.850153     ...      46.596281   \n",
      "22   17.282690  10.115465   6.647645   4.584173     ...      71.798438   \n",
      "23   13.153677  47.998632  31.703460  39.995298     ...      43.703518   \n",
      "24   17.925136  27.161072  12.086775  19.370082     ...      54.384309   \n",
      "25   17.838801  10.981210   6.661229   7.280527     ...      54.647708   \n",
      "26   17.019866  41.637886  20.846573  27.519134     ...      53.008267   \n",
      "27   19.096218  11.446536   5.774577   5.233502     ...      62.651263   \n",
      "28   21.593528  10.633671   7.480538   2.913930     ...      54.721608   \n",
      "29   17.469966  14.493850  12.627473  12.534995     ...      51.054033   \n",
      "..         ...        ...        ...        ...     ...            ...   \n",
      "702  19.707079  14.175855   7.793198   8.418344     ...      46.885922   \n",
      "703  26.034900  13.297669  11.183289   6.495988     ...      59.558485   \n",
      "704  17.791012  17.429973  11.092126   9.504983     ...      51.774742   \n",
      "705  14.216435  28.204049  21.058925  16.999195     ...      50.800897   \n",
      "706  19.299122  12.798198   6.020435   7.983759     ...      53.811339   \n",
      "707  18.567557  19.669436  11.378682  10.614476     ...      43.974798   \n",
      "708  24.052414  12.136136   4.704951   7.695014     ...      42.703863   \n",
      "709  18.504412  19.619213   8.830679  10.108099     ...      59.530856   \n",
      "710  18.833418  18.716682   4.825090   7.043076     ...      42.377988   \n",
      "711  20.886355  16.096990   7.898156   7.978695     ...      56.237899   \n",
      "712  21.451943  13.837203   6.912413   6.749313     ...      41.702201   \n",
      "713  23.275282  12.930712   5.879861   7.848120     ...      58.007638   \n",
      "714  16.241559  10.434464   7.708893   3.213734     ...      67.851573   \n",
      "715  19.741248  15.487356   8.008154   8.879574     ...      46.862594   \n",
      "716  21.013053  13.253157   5.846589   5.893255     ...      50.227757   \n",
      "717  21.312640  13.853216   5.683371   8.388437     ...      34.822896   \n",
      "718  20.267272  12.151963   6.683382   6.254675     ...      50.198416   \n",
      "719  19.457919  13.088708   6.500652   6.235584     ...      28.460563   \n",
      "720  19.038068  20.181883  12.038245  13.709664     ...      47.998061   \n",
      "721  18.050326  17.691710  16.496324  14.045783     ...      76.476793   \n",
      "722  20.557303  15.633988   8.079107   6.592254     ...      41.162109   \n",
      "723  20.633971  14.069264   6.237184   7.063112     ...      47.629891   \n",
      "724  21.752672  19.654449  10.835355   9.163334     ...      44.465926   \n",
      "725  19.676202  17.121161  12.727446  10.363437     ...      59.459092   \n",
      "726  17.296214  14.595042  11.066092   7.646059     ...      53.004354   \n",
      "727  15.588096  24.405605  19.367029  22.673595     ...      52.986383   \n",
      "728  23.085672  14.294058   6.086502   4.949125     ...      23.196302   \n",
      "729  23.735198  12.770568   8.694306   8.900699     ...      45.622688   \n",
      "730  22.179908  13.681724   5.042491   5.148277     ...      45.101238   \n",
      "731  18.743218  12.112609   6.963999   6.359666     ...      49.324831   \n",
      "\n",
      "     B19001009  B19001010   B19001011   B19001012   B19001013   B19001014  \\\n",
      "0    53.306757  42.318307   83.167229   89.249208  102.141470   52.872330   \n",
      "1    50.093078  40.700626   92.612963  117.363344  113.344051   75.774243   \n",
      "2    47.322923  42.505211   70.420610   90.033143   98.677692   54.703249   \n",
      "3    48.681562  43.873381   84.717507  112.204444  127.137252   83.019904   \n",
      "4    51.761414  47.310187   81.902582   93.793717  130.103014   71.982704   \n",
      "5    46.504580  47.750539   90.247845  122.294810  160.998114  100.372665   \n",
      "6    38.216597  35.938423   72.751062   98.274145  132.154395  102.318122   \n",
      "7    30.309321  17.023043   15.569857   53.975503   12.455885    0.000000   \n",
      "8    53.871001  26.675003   64.707721   87.110555  108.679796   64.916120   \n",
      "9    36.246108  31.909623   64.438383   87.488833  117.364952   93.519131   \n",
      "10   58.545491  55.644476   83.116591  111.426499  110.126044   59.083179   \n",
      "11   42.449136  40.834918   75.684444  106.346593  141.164155   90.675894   \n",
      "12   41.293224  43.411661   67.235929   82.879771   85.193756   54.166802   \n",
      "13   49.151211  39.792328   89.370496  104.826314  129.196981   73.487721   \n",
      "14   44.785100  34.452900   69.522209  108.311991  148.246534  122.247254   \n",
      "15   61.476252  42.423412   89.027483   99.924611  129.189226   60.653828   \n",
      "16   43.689377  38.801924   80.520134  108.194504  138.952796  101.682717   \n",
      "17   55.112792  48.358773   83.006889   83.614751   70.174254   54.437390   \n",
      "18   51.440376  46.688856   89.636176  107.219098  121.404797   58.556180   \n",
      "19   46.921467  41.634541   90.758894   85.361824   96.596541   60.028638   \n",
      "20   53.008806  45.963796   86.227984  112.646771  129.182975   92.318982   \n",
      "21   44.285347  35.675986   68.542601   82.574350   93.842041   62.319694   \n",
      "22   54.207896  44.977965   94.975319  100.599454   92.616810   48.999524   \n",
      "23   41.308042  43.007159   74.816857  107.545751  125.456115   77.323751   \n",
      "24   43.895532  45.573736   87.895951  112.387246  132.578141   69.330816   \n",
      "25   54.364743  50.509338   79.902377   79.725523   91.044143   37.351443   \n",
      "26   42.559706  36.665646   68.585426   87.913350  102.571954   52.625536   \n",
      "27   57.377049  44.065939   85.300699  107.014019  115.050916   46.280652   \n",
      "28   58.190300  58.848155   87.733987  107.230429   94.671371   60.403086   \n",
      "29   58.660227  54.462150   96.014084  122.443913  124.452670   71.480161   \n",
      "..         ...        ...         ...         ...         ...         ...   \n",
      "702  43.934703  41.295817   78.818153  101.063841  124.932806   83.116436   \n",
      "703  60.325004  52.276560   90.372528   84.700291   66.457152   41.698605   \n",
      "704  48.264735  41.690982   85.227078  112.328791  126.085613   76.971268   \n",
      "705  42.014261  40.741713   75.565072  104.833660  103.924697   67.667199   \n",
      "706  49.475941  45.783707   82.023186  103.128474  123.812927   72.526600   \n",
      "707  52.005284  40.234252   74.705724  108.639493  126.161615   91.888859   \n",
      "708  54.506438  57.349785   89.484979  122.854077  123.283262   71.834764   \n",
      "709  51.115986  49.183467   93.486310  108.151398  128.538598   71.085344   \n",
      "710  52.721430  44.587267   95.701948   94.496887  145.912834   74.211689   \n",
      "711  50.547599  41.191859   85.901358  116.008218  119.880578   87.674958   \n",
      "712  41.933896  36.951149   74.495889   99.108627  127.975679   93.103405   \n",
      "713  57.624327  56.758330   96.764576  118.726842  126.080722   61.272874   \n",
      "714  62.479887  35.274897   91.491942   84.511226   75.847216   36.760155   \n",
      "715  52.108338  43.875177   80.064012   97.846403  114.596946   65.970324   \n",
      "716  53.778340  45.066422   80.433691   97.355249   98.481043   48.495765   \n",
      "717  39.605440  46.256165   74.652518   77.940517   86.309969   94.380511   \n",
      "718  51.594225  43.781345   83.421924  105.610829  125.231282   76.197393   \n",
      "719  31.513019  28.432000   62.700143   89.210487  130.767253  114.913116   \n",
      "720  48.341481  42.644742   79.309927  108.369359  113.076239   78.118056   \n",
      "721  61.558168  49.653406   79.566004  104.957806   90.039180   52.591923   \n",
      "722  40.422908  36.963083   73.874023   93.504239  123.418848   94.531758   \n",
      "723  52.108239  44.593723   83.646438  109.567725   91.236859   56.131162   \n",
      "724  62.173206  53.561229  100.180149  106.551254  132.387188   65.336790   \n",
      "725  52.731721  51.780375   86.572438  106.686600  102.201685   58.235934   \n",
      "726  62.235123  52.133527   91.727141  111.059506  119.013062   65.834543   \n",
      "727  40.582446  44.559795   72.603479   90.467844   97.478765   57.165970   \n",
      "728  32.359254  22.123163   71.570084  116.807000  181.442959  131.996038   \n",
      "729  46.033703  41.238526   85.628168   93.094945  129.949308   85.833676   \n",
      "730  57.863929  57.000288   83.485270   99.222723  162.364456   61.126571   \n",
      "731  48.406921  42.351354   77.122990   93.503211  107.249387   73.718077   \n",
      "\n",
      "      B19001015   B19001016   B19001017  \n",
      "0     36.440765   23.446284   21.197485  \n",
      "1     33.000508   33.169741   24.792689  \n",
      "2     20.125056   11.890525   16.537397  \n",
      "3     43.731067   38.851729   40.427349  \n",
      "4     36.118530   31.603714   19.648989  \n",
      "5     56.045708   39.017601   28.859106  \n",
      "6     66.729965   71.766845   60.436761  \n",
      "7      0.000000    0.000000    0.000000  \n",
      "8     40.637699   16.359279   10.003126  \n",
      "9     63.997025   80.800359  102.752258  \n",
      "10    32.311309   26.621818   19.406792  \n",
      "11    53.620803   57.983986   48.642299  \n",
      "12    23.074667   21.054004   20.988821  \n",
      "13    29.033029   22.560372   16.634218  \n",
      "14    79.993836   91.045181   72.252024  \n",
      "15    23.507642   22.685217   13.090261  \n",
      "16    62.895245   62.796976   45.108501  \n",
      "17    25.530190   16.547346   12.359854  \n",
      "18    36.313554   27.935269   17.766556  \n",
      "19    24.121599   19.385395    8.921687  \n",
      "20    47.994129   35.249511   20.988258  \n",
      "21    32.534324   27.021312   32.035887  \n",
      "22    23.343186   17.273050   15.678033  \n",
      "23    45.876159   39.469653   34.093758  \n",
      "24    41.378225   34.927627   26.012167  \n",
      "25    18.923316   13.829938   13.087153  \n",
      "26    26.599816   25.183711   18.485915  \n",
      "27    25.434951   18.722316   15.891137  \n",
      "28    27.629926   16.506190   13.994378  \n",
      "29    37.940685   25.188462   17.582269  \n",
      "..          ...         ...         ...  \n",
      "702   48.432709   42.213690   30.602163  \n",
      "703   25.908324   10.961214   14.180592  \n",
      "704   37.829117   31.667296   22.184271  \n",
      "705   38.136021   35.388935   36.701881  \n",
      "706   38.192790   31.014769   26.774655  \n",
      "707   54.495085   55.652316   65.225777  \n",
      "708   42.650215   27.950644   19.313305  \n",
      "709   35.650034   33.897420   27.931567  \n",
      "710   43.382205   35.549307   34.143402  \n",
      "711   40.172039   40.733679   18.755820  \n",
      "712   58.539382   65.700758   70.329729  \n",
      "713   31.587615   24.702225   19.406863  \n",
      "714   17.946877   15.793252   13.416838  \n",
      "715   40.551019   36.939550   29.101829  \n",
      "716   25.113878   23.174048   18.774789  \n",
      "717   40.427440   32.730534   14.272904  \n",
      "718   45.126434   37.960739   38.303605  \n",
      "719   86.187529  116.154420  145.665245  \n",
      "720   45.937538   36.978304   26.877702  \n",
      "721   24.789030   21.398433   15.672092  \n",
      "722   61.899591   73.803477   65.893113  \n",
      "723   24.441155   25.352006   12.751907  \n",
      "724   36.732721   23.902632   20.958742  \n",
      "725   30.443055   17.463985   15.561294  \n",
      "726   27.634253   17.590711    7.837446  \n",
      "727   27.706620   19.347445   15.033032  \n",
      "728  106.653459   84.530296   76.027737  \n",
      "729   49.390327   47.814769   31.031648  \n",
      "730   29.939545   24.085980   19.192016  \n",
      "731   40.966917   44.925312   52.695060  \n",
      "\n",
      "[732 rows x 190 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=1.496e+00, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=1.098e+00, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=7.329e-01, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=6.051e-01, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=5.739e-01, with an active set of 12 regressors, and the smallest cholesky pivot element being 9.483e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=5.736e-01, with an active set of 12 regressors, and the smallest cholesky pivot element being 9.483e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=5.579e-01, with an active set of 12 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=5.483e-01, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 23 iterations, i.e. alpha=5.383e-01, with an active set of 17 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:339: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 25 iterations, alpha=5.917e-01, previous alpha=5.383e-01, with an active set of 16 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=4.100e-01, with an active set of 16 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 27 iterations, i.e. alpha=2.867e-01, with an active set of 27 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 44 iterations, i.e. alpha=2.050e-01, with an active set of 36 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 45 iterations, i.e. alpha=2.013e-01, with an active set of 37 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:339: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 46 iterations, alpha=1.986e-01, previous alpha=1.960e-01, with an active set of 37 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 53 iterations, i.e. alpha=1.426e-01, with an active set of 47 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 87 iterations, i.e. alpha=7.131e-02, with an active set of 67 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 87 iterations, i.e. alpha=7.126e-02, with an active set of 67 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 92 iterations, i.e. alpha=6.413e-02, with an active set of 72 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:339: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 106 iterations, alpha=5.744e-02, previous alpha=5.107e-02, with an active set of 83 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=1.439e+00, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=1.037e+00, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:339: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 15 iterations, alpha=7.202e-01, previous alpha=7.200e-01, with an active set of 12 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=6.916e-01, with an active set of 8 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=3.645e-01, with an active set of 17 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 22 iterations, i.e. alpha=3.456e-01, with an active set of 20 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 46 iterations, i.e. alpha=1.867e-01, with an active set of 38 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 50 iterations, i.e. alpha=1.734e-01, with an active set of 40 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 50 iterations, i.e. alpha=1.709e-01, with an active set of 40 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 51 iterations, i.e. alpha=1.692e-01, with an active set of 41 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:339: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 56 iterations, alpha=1.668e-01, previous alpha=1.607e-01, with an active set of 45 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=1.572e+00, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=1.132e+00, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=7.640e-01, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 26 iterations, i.e. alpha=3.863e-01, with an active set of 24 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 26 iterations, i.e. alpha=3.863e-01, with an active set of 24 regressors, and the smallest cholesky pivot element being 5.053e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 28 iterations, i.e. alpha=3.560e-01, with an active set of 24 regressors, and the smallest cholesky pivot element being 5.053e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 54 iterations, i.e. alpha=1.932e-01, with an active set of 36 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 59 iterations, i.e. alpha=1.737e-01, with an active set of 41 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:339: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 64 iterations, alpha=1.702e-01, previous alpha=1.687e-01, with an active set of 45 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=1.644e+00, with an active set of 4 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=1.178e+00, with an active set of 7 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B01001036' 2.784856986420159]\n",
      "['B01001037' 0.9234930857404328]\n",
      "['B01001038' 0.9491459380764333]\n",
      "['B02001005' 0.3919782979991068]\n",
      "['B13014026' 0.22147975335090184]\n",
      "['B13014027' 0.05121418112617723]\n",
      "['B19001017' 1.6058830181449382]\n",
      "training data MSE\n",
      "22525.63625144556\n",
      "testing data MSE\n",
      "41573.80112905681\n",
      "training data R-square\n",
      "0.2227648778602469\n",
      "testing data R-square\n",
      "0.1753817900469531\n",
      "y interecept:\n",
      "2.8174754145509553\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=9.316e-01, with an active set of 9 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=8.155e-01, with an active set of 10 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:339: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 32 iterations, alpha=3.203e-01, previous alpha=3.135e-01, with an active set of 25 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=1.896e+00, with an active set of 2 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=9.481e-01, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=8.251e-01, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=6.529e-01, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:339: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 12 iterations, alpha=7.347e-01, previous alpha=5.991e-01, with an active set of 11 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=1.147e+00, with an active set of 4 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=8.014e-01, with an active set of 7 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=8.010e-01, with an active set of 7 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=5.693e-01, with an active set of 10 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=5.099e-01, with an active set of 11 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=3.948e-01, with an active set of 17 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:339: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 32 iterations, alpha=3.137e-01, previous alpha=3.116e-01, with an active set of 27 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=5.644e-01, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 25 iterations, i.e. alpha=2.822e-01, with an active set of 23 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:339: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 37 iterations, alpha=2.062e-01, previous alpha=1.984e-01, with an active set of 34 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=1.372e+00, with an active set of 4 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=9.825e-01, with an active set of 8 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Thu Oct  4 08:56:44 2018\n",
    "\n",
    "@author: sridh\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.linear_model import LassoLarsCV\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.datasets import make_regression\n",
    "\n",
    "csvfile = 'finalmaster-ratios.csv'\n",
    "alldata=pandas.read_csv(csvfile) \n",
    "print(alldata)\n",
    "\n",
    "allvariablenames = list(alldata.columns.values)\n",
    "newdata = alldata.drop(columns = ['# Purchases', 'B01001001', 'B01001002', 'B01001003', 'B01001004', 'B01001005', 'B01001006', 'B01001007' ] )\n",
    "\n",
    "listofallpredictors = list(newdata.columns.values)\n",
    "\n",
    "predictors = newdata[listofallpredictors]  \n",
    "target = alldata['# Purchases']\n",
    "                 \n",
    "pred_train, pred_test, tar_train, tar_test = train_test_split(predictors, target, test_size=.3, random_state=123)\n",
    "\n",
    "#myarray1 = np.asarray(pred_train)\n",
    "#myarray2=np.asarray(tar_train,tar_test)\n",
    "#X, y = make_regression(pred_train,tar_train)\n",
    "model=LassoLarsCV(cv=10).fit(pred_train,tar_train)\n",
    "\n",
    "predictors_model=pd.DataFrame(listofallpredictors)\n",
    "#predictors_model.columns = ['label']\n",
    "predictors_model['coeff'] = model.coef_\n",
    "\n",
    "for index, row in predictors_model.iterrows():\n",
    "    if row['coeff'] > 0:\n",
    "        print(row.values)\n",
    "\n",
    "\n",
    "train_error = mean_squared_error(tar_train, model.predict(pred_train))\n",
    "print ('training data MSE')\n",
    "print(train_error)\n",
    "\n",
    "test_error=mean_squared_error(tar_test, model.predict(pred_test))\n",
    "print ('testing data MSE')\n",
    "print(test_error)\n",
    "\n",
    "rsquared_train=model.score(pred_train,tar_train)\n",
    "print ('training data R-square')\n",
    "print(rsquared_train)\n",
    "\n",
    "\n",
    "rsquared_test=model.score(pred_test,tar_test)\n",
    "print ('testing data R-square')\n",
    "print(rsquared_test)   \n",
    "\n",
    "print(\"y interecept:\")\n",
    "print(model.intercept_)\n",
    "\n",
    "             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
